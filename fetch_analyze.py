#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Tue Oct 11 19:24:57 2025

@author: stellakao

å¤–è³‡é€£çºŒå…©å¤©éƒ½é€²å‰10åçš„å€‹è‚¡åˆ†æï¼ˆäº¤é›†ç‰ˆæœ¬ï¼Œå« JSON/CSV è¼¸å‡ºï¼Œé©ç”¨ GitHub Actionsï¼‰
"""
import os
import json
import math
import time
import requests
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta, timezone

# --- è·¯å¾‘èˆ‡æ™‚é–“ ---
TPE_TZ = timezone(timedelta(hours=8))
NOW_TPE = datetime.now(TPE_TZ)
OUT_LATEST = Path("data/latest.json")
OUT_HISTORY_DIR = Path("data/history")
OUT_EXPORT_DIR = Path("exports")
OUT_HISTORY_DIR.mkdir(parents=True, exist_ok=True)
OUT_EXPORT_DIR.mkdir(parents=True, exist_ok=True)

# --- HTTP Sessionï¼ˆé€¾æ™‚/é‡è©¦/UAï¼‰---
SESSION = requests.Session()
SESSION.headers.update({
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
})

def http_get(url, params=None, retries=3, timeout=30):
    last_err = None
    for i in range(retries):
        try:
            r = SESSION.get(url, params=params, timeout=timeout)
            r.raise_for_status()
            return r
        except Exception as e:
            last_err = e
            time.sleep(1.2 * (i + 1))
    raise last_err

def to_number(x):
    """å°‡ '1,234' / '-' / None å®‰å…¨è½‰ç‚º floatã€‚"""
    if x is None:
        return 0.0
    if isinstance(x, (int, float)):
        return float(x)
    s = str(x).strip().replace(',', '')
    if s in {'', '-'}:
        return 0.0
    try:
        return float(s)
    except:
        return 0.0

# ---------------------------------------------------------
# æŠ“è³‡æ–™ï¼šTWSE / TPEx
# ---------------------------------------------------------
def get_twse_foreign_data(date):
    """
    å¾è­‰äº¤æ‰€å®˜ç¶²æŠ“å–å¤–è³‡è²·è³£è¶…è³‡æ–™ (å®Œå…¨å…è²»!)
    åƒæ•¸:
        date: æ—¥æœŸå­—ä¸²,æ ¼å¼ 'YYYYMMDD'
    """
    url = "https://www.twse.com.tw/rwd/zh/fund/T86"
    params = {'date': date, 'selectType': 'ALL', 'response': 'json'}
    try:
        response = http_get(url, params=params)
        data = response.json()
        if 'data' not in data or len(data['data']) == 0:
            return None
        df = pd.DataFrame(data['data'], columns=data['fields'])
        # åªä¿ç•™å¤–è³‡è³‡æ–™
        df = df[['è­‰åˆ¸ä»£è™Ÿ', 'è­‰åˆ¸åç¨±',
                 'å¤–é™¸è³‡è²·é€²è‚¡æ•¸(ä¸å«å¤–è³‡è‡ªç‡Ÿå•†)',
                 'å¤–é™¸è³‡è³£å‡ºè‚¡æ•¸(ä¸å«å¤–è³‡è‡ªç‡Ÿå•†)',
                 'å¤–é™¸è³‡è²·è³£è¶…è‚¡æ•¸(ä¸å«å¤–è³‡è‡ªç‡Ÿå•†)']].copy()
        df.columns = ['stock_id', 'stock_name', 'buy_shares', 'sell_shares', 'net_shares']
        for col in ['buy_shares', 'sell_shares', 'net_shares']:
            df[col] = df[col].map(to_number)
        df['date'] = date
        df['market'] = 'TWSE'
        return df
    except Exception as e:
        print(f"âš ï¸ æ—¥æœŸ {date} TWSE æŸ¥è©¢å¤±æ•—: {e}")
        return None

def get_tpex_foreign_data(date):
    """
    å¾æ«ƒè²·ä¸­å¿ƒæŠ“å–å¤–è³‡è²·è³£è¶…è³‡æ–™ (ä¸Šæ«ƒè‚¡ç¥¨)
    åƒæ•¸:
        date: æ—¥æœŸå­—ä¸²,æ ¼å¼ 'YYYYMMDD'
    """
    # è½‰æ›ç‚ºæ°‘åœ‹å¹´æ ¼å¼
    year = int(date[:4]) - 1911
    month = date[4:6]
    day = date[6:8]
    date_tw = f"{year}/{month}/{day}"

    url = "https://www.tpex.org.tw/web/stock/3insti/daily_trade/3itrade_hedge_result.php"
    params = {'l': 'zh-tw', 'd': date_tw, 'se': 'AL', 'response': 'json'}
    try:
        response = http_get(url, params=params)
        data = response.json()
        if 'aaData' not in data or len(data['aaData']) == 0:
            return None
        df = pd.DataFrame(data['aaData'])
        # æ¬„ä½ï¼š0ä»£è™Ÿ,1åç¨±,7å¤–è³‡è²·,8å¤–è³‡è³£,9å¤–è³‡è²·è³£è¶…
        df = df[[0, 1, 7, 8, 9]].copy()
        df.columns = ['stock_id', 'stock_name', 'buy_shares', 'sell_shares', 'net_shares']
        for col in ['buy_shares', 'sell_shares', 'net_shares']:
            df[col] = df[col].map(to_number)
        df['date'] = date
        df['market'] = 'TPEx'
        return df
    except Exception as e:
        print(f"âš ï¸ æ«ƒè²·æ—¥æœŸ {date} æŸ¥è©¢å¤±æ•—: {e}")
        return None

# ---------------------------------------------------------
# å–®æ—¥ Top10 èˆ‡æœ€è¿‘äº¤æ˜“æ—¥å°‹æ‰¾
# ---------------------------------------------------------
def get_daily_top10(date):
    """
    å–å¾—å–®æ—¥å¤–è³‡è²·è¶…å‰10å
    åƒæ•¸:
        date: æ—¥æœŸå­—ä¸²,æ ¼å¼ 'YYYYMMDD'
    """
    all_data = []
    df_twse = get_twse_foreign_data(date)
    if df_twse is not None:
        all_data.append(df_twse)
    time.sleep(0.3)
    df_tpex = get_tpex_foreign_data(date)
    if df_tpex is not None:
        all_data.append(df_tpex)

    if not all_data:
        return None

    combined = pd.concat(all_data, ignore_index=True)
    daily_result = combined.groupby(['stock_id', 'stock_name'], as_index=False).agg(
        buy_shares=('buy_shares', 'sum'),
        sell_shares=('sell_shares', 'sum'),
        net_shares=('net_shares', 'sum')
    )

    daily_top10 = daily_result.sort_values('net_shares', ascending=False).head(10).reset_index(drop=True)
    # è‚¡â†’å¼µ
    daily_top10['è²·å…¥_å¼µ'] = (daily_top10['buy_shares'] / 1000).round(0).astype(int)
    daily_top10['è³£å‡º_å¼µ'] = (daily_top10['sell_shares'] / 1000).round(0).astype(int)
    daily_top10['æ·¨è²·è¶…_å¼µ'] = (daily_top10['net_shares'] / 1000).round(0).astype(int)
    return daily_top10

def find_recent_trading_dates(days=2, lookback=20):
    """å¾€å›æ‰¾æœ€è¿‘çš„å¯ç”¨äº¤æ˜“æ—¥ï¼ˆä»¥ TWSE æœ‰è³‡æ–™ç‚ºæº–ï¼‰"""
    trading_dates = []
    check_date = NOW_TPE
    print("ğŸ” å°‹æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥...")
    for _ in range(lookback):
        date_str = check_date.strftime('%Y%m%d')
        df_twse = get_twse_foreign_data(date_str)
        if df_twse is not None and len(df_twse) > 0:
            trading_dates.append(date_str)
            formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
            print(f"   âœ“ æ‰¾åˆ°äº¤æ˜“æ—¥: {formatted_date}")
            if len(trading_dates) >= days:
                break
        check_date -= timedelta(days=1)
        time.sleep(0.2)
    return trading_dates

# ---------------------------------------------------------
# ä¸»åˆ†æï¼šé€£çºŒ N å¤©äº¤é›†
# ---------------------------------------------------------
def get_consecutive_top10(days=2):
    """
    æ‰¾å‡ºé€£çºŒNå¤©éƒ½åœ¨å‰10åçš„å€‹è‚¡(äº¤é›†)
    """
    print("=" * 70)
    print("ğŸš€ å¤–è³‡é€£çºŒè²·è¶…å‰10åäº¤é›†åˆ†æ")
    print("=" * 70)
    print(f"ğŸ“… ä»Šå¤©: {NOW_TPE.strftime('%Y-%m-%d %H:%M')} (Asia/Taipei)\n")

    trading_dates = find_recent_trading_dates(days=days, lookback=30)

    if len(trading_dates) < days:
        print(f"\nâŒ åªæ‰¾åˆ° {len(trading_dates)} å€‹äº¤æ˜“æ—¥,éœ€è¦ {days} å€‹")
        return None

    print(f"\nğŸ“Š åˆ†ææœ€è¿‘ {days} å€‹äº¤æ˜“æ—¥...\n")
    daily_top10_list = []

    for i, date in enumerate(trading_dates[:days], 1):
        formatted_date = f"{date[:4]}-{date[4:6]}-{date[6:]}"
        print(f"â³ å–å¾—ç¬¬ {i} å¤©å‰10å: {formatted_date}")
        daily_top10 = get_daily_top10(date)
        if daily_top10 is not None:
            daily_top10['rank_date'] = formatted_date
            daily_top10_list.append(daily_top10)
            # é¡¯ç¤ºå‰äº”ååç¨±
            print(f"   âœ“ å‰10å: {', '.join(daily_top10['stock_name'].head(5).tolist())}...")
        else:
            print(f"   âœ— ç„¡æ³•å–å¾—è³‡æ–™")
            return None
        time.sleep(0.3)

    if len(daily_top10_list) < days:
        print(f"\nâŒ è³‡æ–™ä¸å®Œæ•´")
        return None

    # äº¤é›†
    print(f"\nğŸ” å°‹æ‰¾é€£çºŒ {days} å¤©éƒ½åœ¨å‰10åçš„å€‹è‚¡...")
    common_stocks = set(daily_top10_list[0]['stock_id'])
    for i in range(1, days):
        day_stocks = set(daily_top10_list[i]['stock_id'])
        common_stocks &= day_stocks
        print(f"   ç¬¬ 1-{i+1} å¤©äº¤é›†: {len(common_stocks)} æª”")

    if not common_stocks:
        print(f"\nâŒ æ²’æœ‰å€‹è‚¡é€£çºŒ {days} å¤©éƒ½åœ¨å‰10å")
        # ä»å›å‚³ç©ºçµæœèˆ‡æ¯æ—¥æ¦œå–®ï¼Œæ–¹ä¾¿å‰ç«¯é¡¯ç¤º
        return pd.DataFrame(), daily_top10_list

    print(f"\nâœ… æ‰¾åˆ° {len(common_stocks)} æª”é€£çºŒ {days} å¤©éƒ½åœ¨å‰10åçš„å€‹è‚¡\n")

    result_list = []
    for stock_id in common_stocks:
        stock_name = daily_top10_list[0].loc[
            daily_top10_list[0]['stock_id'] == stock_id, 'stock_name'
        ].values[0]

        stock_info = {'stock_id': stock_id, 'stock_name': stock_name}
        total_net_buy = 0

        for i, daily_data in enumerate(daily_top10_list, 1):
            stock_row = daily_data[daily_data['stock_id'] == stock_id]
            if len(stock_row) > 0:
                # åæ¬¡ï¼ˆä¾ç•¶æ—¥æ·¨è²·è¶…å¼µæ•¸æ’åºï¼‰
                rank = int((daily_data['æ·¨è²·è¶…_å¼µ'] >= stock_row.iloc[0]['æ·¨è²·è¶…_å¼µ']).sum())
                net_buy = int(stock_row.iloc[0]['æ·¨è²·è¶…_å¼µ'])

                stock_info[f'day{i}_rank'] = rank
                stock_info[f'day{i}_net_buy'] = net_buy
                stock_info[f'day{i}_date'] = daily_data.iloc[0]['rank_date']
                total_net_buy += net_buy

        stock_info['total_net_buy'] = int(total_net_buy)
        stock_info['avg_net_buy'] = float(total_net_buy / days)
        result_list.append(stock_info)

    result = pd.DataFrame(result_list).sort_values('total_net_buy', ascending=False).reset_index(drop=True)
    return result, daily_top10_list

# ---------------------------------------------------------
# è¼¸å‡º JSONï¼ˆçµ¦å‰ç«¯ä½¿ç”¨ï¼‰
# ---------------------------------------------------------
def write_json_payload(result_df, daily_top10_list):
    # trading_datesï¼ˆç”±è¿‘åˆ°é ï¼‰
    trading_dates = [d.iloc[0]['rank_date'] for d in daily_top10_list]

    stocks = []
    for _, r in result_df.iterrows():
        item = {
            "stock_id": r["stock_id"],
            "stock_name": r["stock_name"],
            "total_net_buy": int(r["total_net_buy"]),
            "avg_net_buy": float(r["avg_net_buy"]),
            "per_day": {}
        }
        # day1/day2...
        i = 1
        while f"day{i}_date" in r:
            item["per_day"][f"day{i}"] = {
                "date": r[f"day{i}_date"],
                "rank": int(r[f"day{i}_rank"]),
                "net_buy_lots": int(r[f"day{i}_net_buy"])
            }
            i += 1
        stocks.append(item)

    payload = {
        "mode": "intersection_top10_per_day",
        "generated_at_utc": datetime.utcnow().strftime("%Y-%m-%d %H:%M:%S"),
        "timezone": "Asia/Taipei",
        "params": {"days": len(daily_top10_list), "top_n": 10},
        "trading_dates": trading_dates,
        "count_intersection": int(len(result_df)),
        "stocks": stocks
    }

    OUT_LATEST.parent.mkdir(parents=True, exist_ok=True)
    OUT_LATEST.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"[OK] å¯«å…¥ {OUT_LATEST}")

    # ä»¥æœ€è¿‘ä¸€å€‹äº¤æ˜“æ—¥å‘½åæ­·å²æª”
    last_trade = trading_dates[0].replace('-', '')
    out_history = OUT_HISTORY_DIR / f"{last_trade}.json"
    out_history.write_text(json.dumps(payload, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"[OK] å¯«å…¥ {out_history}")

# ---------------------------------------------------------
# ä¸»ç¨‹å¼
# ---------------------------------------------------------
if __name__ == "__main__":
    # é€£çºŒå¤©æ•¸å¯ç”±ç’°å¢ƒè®Šæ•¸æ§åˆ¶ï¼ˆé è¨­ 2ï¼‰
    days = int(os.getenv("DAYS", "2"))

    result_data = get_consecutive_top10(days=days)

    if result_data is not None:
        result, daily_top10_list = result_data

        print("=" * 70)
        print(f"ğŸ‰ é€£çºŒ {days} å¤©éƒ½åœ¨å¤–è³‡è²·è¶…å‰10åçš„å€‹è‚¡ (äº¤é›†)")
        print("=" * 70)

        if result is not None and len(result) > 0:
            # æ•´ç†çµ‚ç«¯æ©Ÿé¡¯ç¤º
            display = pd.DataFrame()
            display['ä»£è™Ÿ'] = result['stock_id']
            display['è‚¡ç¥¨åç¨±'] = result['stock_name']
            display['ç¬¬1å¤©æ—¥æœŸ'] = result['day1_date']
            display['ç¬¬1å¤©æ’å'] = result['day1_rank'].astype(int)
            display['ç¬¬1å¤©è²·è¶…(å¼µ)'] = result['day1_net_buy'].astype(int)
            display['ç¬¬2å¤©æ—¥æœŸ'] = result.get('day2_date', pd.NA)
            display['ç¬¬2å¤©æ’å'] = result.get('day2_rank', pd.NA)
            display['ç¬¬2å¤©è²·è¶…(å¼µ)'] = result.get('day2_net_buy', pd.NA)
            display['åˆè¨ˆè²·è¶…(å¼µ)'] = result['total_net_buy'].astype(int)

            display['æ’åè®ŠåŒ–'] = display.apply(
                lambda row: (
                    "â†’" if pd.isna(row['ç¬¬2å¤©æ’å']) else
                    (f"â†‘{abs(int(row['ç¬¬2å¤©æ’å']) - int(row['ç¬¬1å¤©æ’å']))}"
                     if int(row['ç¬¬2å¤©æ’å']) < int(row['ç¬¬1å¤©æ’å'])
                     else (f"â†“{int(row['ç¬¬2å¤©æ’å']) - int(row['ç¬¬1å¤©æ’å'])}"
                           if int(row['ç¬¬2å¤©æ’å']) > int(row['ç¬¬1å¤©æ’å'])
                           else "â†’"))
                ), axis=1
            )

            pd.set_option('display.unicode.east_asian_width', True)
            pd.set_option('display.max_columns', None)
            pd.set_option('display.width', 180)

            print("\n" + display.to_string())

            # CSV åŒ¯å‡ºï¼ˆæª”åä¸­æ–‡ä¿æŒ UTF-8-sigï¼ŒWindows å¯é–‹ï¼‰
            timestamp = NOW_TPE.strftime('%Y%m%d_%H%M')
            csv_path = OUT_EXPORT_DIR / f'å¤–è³‡é€£çºŒå‰10åäº¤é›†_{timestamp}.csv'
            result.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"\nğŸ’¾ çµæœå·²å„²å­˜: {csv_path}")

            # çµ±è¨ˆè³‡è¨Š
            print("\n" + "=" * 70)
            print("ğŸ“ˆ çµ±è¨ˆè³‡è¨Š")
            print("=" * 70)
            print(f"âœ… é€£çºŒé€²æ¦œ: {len(result)} æª”")
            print(f"ğŸ“Š ç¸½è²·è¶…: {int(display['åˆè¨ˆè²·è¶…(å¼µ)'].sum()):,} å¼µ")
            print(f"ğŸ“Š å¹³å‡è²·è¶…: {display['åˆè¨ˆè²·è¶…(å¼µ)'].mean():,.0f} å¼µ/æª”")

            # é¡¯ç¤ºæ¯æ—¥å®Œæ•´å‰10åï¼ˆä¾›åƒè€ƒï¼‰
            print("\n" + "=" * 70)
            print("ğŸ“‹ å„æ—¥å®Œæ•´å‰10å (â­ç‚ºäº¤é›†å€‹è‚¡)")
            print("=" * 70)
            common_ids = set(result['stock_id'])
            for i, daily_data in enumerate(daily_top10_list, 1):
                date = daily_data.iloc[0]['rank_date']
                print(f"\nã€ç¬¬ {i} å¤©ã€‘{date}")
                print("-" * 70)
                for rank, (_, row) in enumerate(daily_data.iterrows(), 1):
                    is_common = "â­" if row['stock_id'] in common_ids else "  "
                    print(f"   {is_common} {rank:2d}. {row['stock_name']:8s} ({row['stock_id']}) "
                          f"- è²·è¶… {row['æ·¨è²·è¶…_å¼µ']:>8,} å¼µ")

        else:
            print("\nâŒ æ²’æœ‰å€‹è‚¡é€£çºŒå…©å¤©éƒ½åœ¨å‰10å")

        # ç„¡è«–æ˜¯å¦æœ‰äº¤é›†ï¼Œéƒ½å¯« JSONï¼ˆæ–¹ä¾¿å‰ç«¯é¡¯ç¤ºï¼‰
        write_json_payload(result if result is not None else pd.DataFrame(), daily_top10_list)

    else:
        print("\nâŒ åˆ†æå¤±æ•—")
        # å¤±æ•—æ™‚ï¼šé¿å…è®“ GitHub Actions å› ç„¡è¼¸å‡ºè€Œä¸­æ­¢ï¼Œå¯è¦–éœ€æ±‚æ±ºå®šæ˜¯å¦ exit 1
        # import sys; sys.exit(1)

    print("\nâœ¨ æŸ¥è©¢å®Œæˆ!")
